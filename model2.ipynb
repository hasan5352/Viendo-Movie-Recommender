{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform datasets to dfs\n",
    "def get_datasets_as_dfs(directory: str):\n",
    "    \"\"\" gets datasets from specified directory, transforms into pandas dataframes and returns dictionary of dfs\n",
    "        Returns: {dataset_names: dataframes}\n",
    "    \"\"\"\n",
    "    dataframes = {}\n",
    "\n",
    "    for filename in os.listdir(directory):               # get all files in specified dir\n",
    "        filepath = os.path.join(directory, filename)     # join file name with directory to acess file (directory/filenane)\n",
    "        df = pd.read_csv(filepath)                      # construct df\n",
    "        df_name = os.path.splitext(filename)[0]          # remove extension from filename and return file name \n",
    "        dataframes[df_name] = df\n",
    "\n",
    "    return dataframes\n",
    "\n",
    "dataframes = get_datasets_as_dfs('data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finding common columns to use those for merging dfs\n",
    "common_columns = set(dataframes['tmdb_5000_credits'].columns).intersection(set(dataframes['tmdb_5000_movies'].columns))\n",
    "# mergining dfs on the 0eth common column\n",
    "movies = dataframes['tmdb_5000_credits'].merge(dataframes['tmdb_5000_movies'], on=list(common_columns)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Auxillary Functions\n",
    "def extract_genres_keywords(listOf_Dicts):\n",
    "    \"\"\" extracts genres and keywords of every movies from respective column of df (list of dicts).\n",
    "        Returns: list of genres\n",
    "    \"\"\"\n",
    "    genres = []\n",
    "    for dictionary in eval(listOf_Dicts):\n",
    "        genres.append(dictionary['name'])\n",
    "\n",
    "    return genres\n",
    "\n",
    "def extract_cast(listOf_Dicts):\n",
    "    \"\"\" extracts top given number of actors for every movie from cast column of df (list of dicts).\n",
    "        Returns: list of 3 actors\n",
    "    \"\"\"\n",
    "    num_actors = 3\n",
    "    cast = []\n",
    "    for i in eval(listOf_Dicts):\n",
    "        cast.append(i['name'])\n",
    "        num_actors -= 1\n",
    "        if num_actors == 0:\n",
    "            break\n",
    "\n",
    "    return cast\n",
    "\n",
    "def extract_director(listOf_Dicts):\n",
    "    \"\"\" extracts director from crew column of df (list of dicts).\n",
    "        Returns: list of 1 director\n",
    "    \"\"\"\n",
    "    director = []\n",
    "    for i in eval(listOf_Dicts):\n",
    "        if i['job'].lower() == 'director':\n",
    "            director.append(i['name'])\n",
    "            break\n",
    "    return director\n",
    "\n",
    "def text_to_words(value):\n",
    "    \"\"\" converts text to list of words - for overview column.\n",
    "        removes spaces from words in a list for all columns\n",
    "        Returns: list of words\n",
    "    \"\"\"\n",
    "    if type(value) == list:\n",
    "        for i, element in enumerate(value):\n",
    "            element = element.replace(' ', '')\n",
    "            value[i] = element\n",
    "        return value\n",
    "    \n",
    "    words = value.split(' ')\n",
    "    return words\n",
    "\n",
    "columns_to_concat = ['crew', 'cast', 'genres', 'keywords', 'overview']\n",
    "def concatColumns_intoOne(row):\n",
    "\n",
    "    merged_vals = []\n",
    "    for column in columns_to_concat:\n",
    "        merged_vals.extend(row[column])\n",
    "\n",
    "    return merged_vals\n",
    "\n",
    "def list_to_str(value):\n",
    "    return ' '.join(value)\n",
    "\n",
    "def stemming_words(text):\n",
    "    \"\"\" stems each word of text to its base word\n",
    "    \"\"\"\n",
    "    stemmer = PorterStemmer()\n",
    "    words = text.split(' ')\n",
    "\n",
    "    for i, word in enumerate(words):\n",
    "        stemmed_word = stemmer.stem(word)\n",
    "        words[i] = stemmed_word\n",
    "\n",
    "    return ' '.join(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DATA PRE PROCESSING\n",
    "\n",
    "# 1. Remove unecessary columns\n",
    "#     necessary columns: 'movie_id', 'title', 'cast', 'crew', 'genres', 'overview', 'keywords'\n",
    "# 2. check how many missing values in each column, if less, then drop those instances\n",
    "# 3. drop duplicate instances\n",
    "# 4. clean and extract genres from genres column\n",
    "# 5. clean and extract keywords from keywords column\n",
    "# 6. clean and extract to cast from cast column\n",
    "# 7. extract director from crew column\n",
    "# 8. convert overview to a list of words to standardize all columns as list of words\n",
    "# 9. remove spaces from words in columns except overview and title \n",
    "# 10. create tags columns from crew, cast, keywords, overview, genres\n",
    "# 11. convert tags to str from list\n",
    "# 12 Stem each tag to its base word.\n",
    "\n",
    "# 1\n",
    "movies = movies[['movie_id', 'title', 'cast', 'crew', 'genres', 'overview', 'keywords']].copy()   # creating copy to avoid errors\n",
    "movies.head()\n",
    "# 2\n",
    "movies.isnull().sum()    # checking missing values = 3 in overview column\n",
    "movies.dropna(inplace=True)         # dropping instances with missing values\n",
    "# 3\n",
    "movies.drop_duplicates(inplace=True)\n",
    "# 4\n",
    "movies['genres'] = movies['genres'].apply(extract_genres_keywords)\n",
    "# 5\n",
    "movies['keywords'] = movies['keywords'].apply(extract_genres_keywords)\n",
    "# 6\n",
    "movies['cast'] = movies['cast'].apply(extract_cast)\n",
    "# 7\n",
    "movies['crew'] = movies['crew'].apply(extract_director)\n",
    "# 8\n",
    "movies['overview'] = movies['overview'].apply(text_to_words)\n",
    "# 9\n",
    "movies['keywords'] = movies['keywords'].apply(text_to_words)\n",
    "movies['genres'] = movies['genres'].apply(text_to_words)\n",
    "movies['cast'] = movies['cast'].apply(text_to_words)\n",
    "movies['crew'] = movies['crew'].apply(text_to_words)\n",
    "# 10\n",
    "movies['tags'] = movies.apply(concatColumns_intoOne, axis=1)\n",
    "movies.drop(columns_to_concat, axis=1, inplace=True)\n",
    "# 11\n",
    "movies['tags'] = movies['tags'].apply(list_to_str).str.lower()\n",
    "# 12\n",
    "movies['tags'] = movies['tags'].apply(stemming_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# VECTORIZATION :- Bag of Words technique\n",
    "#join the tags of each movie which will result in a huge corpus of words. remove the stop words. \n",
    "#fetch most frequent n number of words in the corpus and call it most_frequent_words. \n",
    "# Count the number of times each word in most_frequent_words occurs in each movie tag. \n",
    "# This will result in a list of numbers representing 'tags' of a movie with len(list) = n, where each number is the frequency of \n",
    "#   each word in most_frequent_words occuring in tags. \n",
    "# This list is the vector representation of the movie in n-dimensions\n",
    "\n",
    "vectorizer = CountVectorizer(max_features=5000, stop_words='english')\n",
    "vectors = vectorizer.fit_transform(movies['tags']).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.        , 0.08458258, 0.08718573, ..., 0.04559608, 0.        ,\n",
       "        0.        ],\n",
       "       [0.08458258, 1.        , 0.06063391, ..., 0.02378257, 0.        ,\n",
       "        0.02615329],\n",
       "       [0.08718573, 0.06063391, 1.        , ..., 0.02451452, 0.        ,\n",
       "        0.        ],\n",
       "       ...,\n",
       "       [0.04559608, 0.02378257, 0.02451452, ..., 1.        , 0.03962144,\n",
       "        0.04229549],\n",
       "       [0.        , 0.        , 0.        , ..., 0.03962144, 1.        ,\n",
       "        0.08714204],\n",
       "       [0.        , 0.02615329, 0.        , ..., 0.04229549, 0.08714204,\n",
       "        1.        ]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# SIMILARITY CALCULATIOn - using cosine similarity\n",
    "# calculating distance of each movie with all other movies\n",
    "# result: matrix of arrays where each array is a movie and each element of the array is the distance of that movie with all other movies\n",
    "\n",
    "similarity_matrix = cosine_similarity(vectors)\n",
    "\n",
    "# Sort every array in the matrix so that we get the closest similarity scores of movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Aliens vs Predator: Requiem',\n",
       " 'Falcon Rising',\n",
       " 'Independence Day',\n",
       " 'Titan A.E.',\n",
       " 'Aliens',\n",
       " 'Battle: Los Angeles',\n",
       " 'Predators',\n",
       " 'Small Soldiers',\n",
       " 'Jupiter Ascending']"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def recommend(movie_name, n):\n",
    "    movie_index = movies[movies['title'] == movie_name].index[0]\n",
    "    distances = similarity_matrix[movie_index]\n",
    "    index_tracker_movies = list(enumerate(distances))\n",
    "    nearest_movie_scores = sorted(index_tracker_movies, reverse=True,key=lambda x: x[1])[1:n]\n",
    "\n",
    "    nearest_movie_indices = [movie[0] for movie in nearest_movie_scores]\n",
    "    \n",
    "    nearest_movie_titles = [movies.iloc[i].title for i in nearest_movie_indices]\n",
    "\n",
    "    return nearest_movie_titles\n",
    "\n",
    "recommend('Avatar', 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movies[movies['title'] == 'Avatar'].index[0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
